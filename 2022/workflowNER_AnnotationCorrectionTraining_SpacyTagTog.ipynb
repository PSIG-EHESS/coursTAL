{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workflowNER_AnnotationCorrectionTraining_SpacyTagTog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chaine de traitement en Python pour adapter le moteur de reconnaissance d'entités nommées de Spacy par entrainement. \n",
        "\n",
        "Il s'agit de :\n",
        "\n",
        "\n",
        "1.   annoter automatiquement en noms de lieux (LOC) et de personnes (PERS) un extrait du texte \"Bel Ami\" de Maupassant en s'appuyant sur le modèle pour le français \"fr_core_news_sm\" proposé par Spacy ;\n",
        "2.   transférer le texte annoté vers l'outil d'annotation TagTog via leur API REST afin de corriger manuellement les annotations créées automatiquement;\n",
        "3.   Corriger manuellement ces annotations en vue de créer un jeu  de données d'entrainement ;\n",
        "4.   Formatter et intégrer les annotations corrigées dans Spacy en tant que jeu de données d'entrainement ;\n",
        "5.  Initialiser un modèle qui sera entrainé de manière incrémentale à partir du jeu d'entrainement ;\n",
        "6.  Initialiser l'entrainement avec les paramètres définis dans le fichier .cfg et entrainement par le biais du CLI de Spacy ;\n",
        "7.  Test du nouveau modèle sur un autre extrait de \"Bel Ami\" de Maupassant.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "htmoCRKpviSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prérequis : Installation ou mise à jour de Spacy et téléchargement du modèle**"
      ],
      "metadata": {
        "id": "CIH6rkzkxA1k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_myBICfwdlt0"
      },
      "outputs": [],
      "source": [
        "!python -m spacy info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy"
      ],
      "metadata": {
        "id": "JEA7X_37drkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download fr_core_news_sm  "
      ],
      "metadata": {
        "id": "jMJpmXfgefSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chargement d'un extrait du premier chapiture de Bel Ami de Maupassant.**\n",
        "A télécharger et enregistrer sur votre ordinateur à partir de : \n",
        "https://github.com/cvbrandoe/coursTAL/blob/master/2022/belAmi_01-01.txt "
      ],
      "metadata": {
        "id": "Hx4PNnqVxTWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VKS7kTaf1xzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Annotation automatiquement en noms de lieux (LOC) et de personnes (PERS) du texte en entrée en s'appuyant sur le modèle pour le français \"fr_core_news_sm\" proposé par Spacy**"
      ],
      "metadata": {
        "id": "Myo_fio_ydfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def get_class_id(label):\n",
        "  \"\"\"\n",
        "  Translates the spaCy label id into the tagtog entity type id\n",
        "  - label: spaCy label id\n",
        "  \"\"\"\n",
        "  choices = {'PER': 'e_1', 'LOC': 'e_2', 'GPE': 'e_2'}\n",
        "  return choices.get(label, None)\n",
        "\n",
        "def get_entities(spans, pipeline):\n",
        "  \"\"\"\n",
        "  Translates a tuple of named entity Span objects (https://spacy.io/api/span) into a \n",
        "  list of tagtog entities (https://docs.tagtog.net/anndoc.html#ann-json). Each entity is\n",
        "  defined by the entity type ID (classId), the part name where the annotation is (part),\n",
        "  the entity offsets and the confidence (annotation status, who created it and probabilty).\n",
        "  - spans: the named entities in the spaCy doc\n",
        "  - pipeline: trained pipeline name\n",
        "  \"\"\"\n",
        "  default_prob = 1\n",
        "  default_part_id = 's1v1'\n",
        "  default_state = 'pre-added'\n",
        "  tagtog_entities = []\n",
        "  for span in spans:\n",
        "    class_id = get_class_id(span.label_)\n",
        "    if class_id is not None:\n",
        "      tagtog_entities.append( {\n",
        "        'classId': class_id,\n",
        "        'part': default_part_id,\n",
        "        'offsets':[{'start': span.start_char, 'text': span.text}],\n",
        "        'confidence': {'state': default_state,'who': ['ml:' + pipeline],'prob': default_prob},\n",
        "        'fields':{},\n",
        "        # this is related to the kb_id (knowledge base ID) field from the Span spaCy object\n",
        "        'normalizations': {}} )\n",
        "  return tagtog_entities\n"
      ],
      "metadata": {
        "id": "UiZpEoo-d9Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#text = \"Quand Georges Duroy parvint au boulevard, il s’arrêta encore, indécis sur ce qu’il allait faire. Il avait envie maintenant de gagner les Champs-Élysées et l’avenue du bois de Boulogne pour trouver un peu d’air frais sous les arbres.\"\n",
        "myfile = open(\"belAmi_01-01.txt\").read().replace(\"’\",\"'\")\n",
        "\n",
        "def read_text(file_name):\n",
        "  with open (file_name, \"r\", encoding=\"utf_8\") as myfile:\n",
        "    lines = list(line for line in (l.strip() for l in myfile) if line)\n",
        "  return str(lines)\n",
        "#myfile = read_text(\"belAmi_01-01.txt\").replace(\"’\",\"'\")\n",
        "\n",
        "pipeline = 'fr_core_news_sm' \n",
        "nlp = spacy.load(pipeline)\n",
        "doc = nlp(myfile)\n",
        "\n",
        "def show_ents(doc): \n",
        "    if doc.ents: \n",
        "        for ent in doc.ents: \n",
        "            print(ent.text+' - ' +str(ent.start_char) +' - '+ str(ent.end_char) +' - '+ent.label_+ ' - '+str(spacy.explain(ent.label_))) \n",
        "            print(\"\\n\")             \n",
        "show_ents(doc)\n"
      ],
      "metadata": {
        "id": "gHOhOZci0vyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. transfer du texte annoté vers l'outil d'annotation TagTog via leur API REST afin de corriger manuellement les annotations**\n",
        "\n",
        "Au préalable, il faut créer un compte utilisateur et un projet dans TagTog (https://www.tagtog.net/) et modifier les informations de connexion ci-dessous.\n",
        "\n",
        "Lors de la configuration (settings) de votre projet sur TagTog, dans la rubrique entities, il faut déclarer les trois catégories d'entités pour l'exercice (dans cet ordre là) :  **Personnages**, **Lieux** et **Misc** (voir diapo #48 du support du cours : https://github.com/cvbrandoe/coursTAL/blob/master/2022/Cours%20TAL%20HN%20-%20ENC%20-%2023_02_2022%20.pdf).\n"
      ],
      "metadata": {
        "id": "lNch1ozT12my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the credentials at tagtog and project name\n",
        "MY_USERNAME = 'ACHANGER'\n",
        "MY_PASSWORD = 'ACHANGER'\n",
        "MY_PROJECT = 'ACHANGER'\n",
        "\n",
        "# API authentication\n",
        "tagtogAPIUrl = \"https://www.tagtog.net/-api/documents/v1\"\n",
        "auth = requests.auth.HTTPBasicAuth(username=MY_USERNAME, password=MY_PASSWORD)\n",
        "\n",
        "# Initialize ann.json (specification: https://docs.tagtog.net/anndoc.html#ann-json)\n",
        "annjson = {}\n",
        "# Set the document as not confirmed, an annotator will manually confirm whether the annotations are correct\n",
        "annjson['anncomplete'] = False\n",
        "annjson['metas'] = {}\n",
        "annjson['relations'] = []                      \n",
        "# Transform the spaCy entities into tagtog entities\n",
        "annjson['entities'] = get_entities(doc.ents, pipeline)\n",
        "\n",
        "print(myfile)\n",
        "print(json.dumps(annjson))\n",
        "\n",
        "# Parameters for the API call \n",
        "# see https://docs.tagtog.net/API_documents_v1.html#examples-import-pre-annotated-plain-text-file\n",
        "params = {'owner': MY_USERNAME, 'project': MY_PROJECT, 'output': 'null', 'format': 'default-plus-annjson'}\n",
        "# Pre-annotated document composed of the content and the annotations\n",
        "files=[('BelAmi_extrait0101.txt', myfile), ('BelAmi_extrait0101.ann.json', json.dumps(annjson))]\n",
        "# POST request to send the pre-annotated document\n",
        "response = requests.post(tagtogAPIUrl, params=params, auth=auth, files=files)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "PJeTbSWg0lUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  Correction manuelle des annotations en vue de créer un jeu  de données d'entrainement**\n",
        "\n",
        "Ensuite télécharger fichier json à partir de tagtog et renommez-le en \"BelAmi_01_01_corrected.ann.json\", ce fichier est traité ci-dessous."
      ],
      "metadata": {
        "id": "cPWGPhPAfX1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "9w8SJskoljHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Formattage et intégration des annotations corrigées dans Spacy en tant que jeu de données d'entrainement**"
      ],
      "metadata": {
        "id": "dBl9pvER3gyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the module\n",
        "import json\n",
        "  # reading the data from the file\n",
        "with open('BelAmi_01_01_corrected.ann.json') as f:\n",
        "    data = f.read()  \n",
        "print(\"Data type before reconstruction : \", type(data))\n",
        "# reconstructing the data as a dictionary\n",
        "js_corrected_training_data = json.loads(data)\n",
        "print(\"Data type after reconstruction : \", type(js_corrected_training_data))\n",
        "print(js_corrected_training_data)"
      ],
      "metadata": {
        "id": "93f8q8qqmEB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_id_inv(label):\n",
        "  \"\"\"\n",
        "  Translates the tagtog entity type id into spaCy label id \n",
        "  - label: tagtog entity type id\n",
        "  \"\"\"\n",
        "  choices = {'e_1': 'PER', 'e_2': 'LOC', 'e_3': 'MISC'}\n",
        "  return choices.get(label, None)"
      ],
      "metadata": {
        "id": "7PqUS4Cun4Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "training_data = {'classes' : ['PER', \"LOC\", \"MISC\"], 'annotations' : []}\n",
        "temp_dict = {}\n",
        "temp_dict['text'] = myfile\n",
        "temp_dict['entities'] = []\n",
        "for example in js_corrected_training_data['entities']:  \n",
        "  #print(example)\n",
        "  start = example['offsets'][0]['start']\n",
        "  end = int(example['offsets'][0]['start']) + len(example['offsets'][0]['text'])\n",
        "  label = get_class_id_inv(example['classId'])\n",
        "  temp_dict['entities'].append((start, end, label))\n",
        "  #print(temp_dict['entities'])\n",
        "training_data['annotations'].append(temp_dict)\n",
        "  \n",
        "print(training_data['annotations'][0])"
      ],
      "metadata": {
        "id": "DvzGn-rpfE_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.  Initialisation du modèle qui sera entrainé de manière incrémentale à partir du jeu d'entrainement** "
      ],
      "metadata": {
        "id": "t8qP3mCG5Oxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"fr\") # load a new spacy model\n",
        "doc_bin = DocBin() # create a DocBin object\n"
      ],
      "metadata": {
        "id": "UeUIP1FWfJn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.util import filter_spans\n",
        "\n",
        "for training_example  in tqdm(training_data['annotations']): \n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp.make_doc(text) \n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents \n",
        "    doc_bin.add(doc)\n",
        "\n",
        "doc_bin.to_disk(\"training_data.spacy\") # save the docbin object\n"
      ],
      "metadata": {
        "id": "BVBN0pOofLib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le fichier de configuration base_config_nermodel.cfg est à télécharger à partir d'ici : https://github.com/cvbrandoe/coursTAL/blob/master/2022/base_config_nermodel.cfg "
      ],
      "metadata": {
        "id": "XQxlbAKG5ty6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "AzziKWBBojHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.  Initialisation de l'entrainement avec les paramètres définis (hyperparamètres) dans le fichier .cfg et entrainement par le biais du CLI de Spacy**"
      ],
      "metadata": {
        "id": "c8mDruj055Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config_nermodel.cfg config.cfg"
      ],
      "metadata": {
        "id": "meQgWoDZoqVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --output ./\n"
      ],
      "metadata": {
        "id": "LYAMJPjdowPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Télécharger l'autre extrait de Bel Ami pour tester le modèle à partir de : https://github.com/cvbrandoe/coursTAL/blob/master/2022/belAmi_01-05.txt"
      ],
      "metadata": {
        "id": "OKvpvkd_CFu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "9-DUygN5zJea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Test du nouveau modèle sur un autre extrait de \"Bel Ami\" de Maupassant**"
      ],
      "metadata": {
        "id": "xC6yamR4I8Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_ner = spacy.load(\"model-best\")\n",
        "\n",
        "test_dataset = open(\"belAmi_01-05.txt\").read().replace(\"’\",\"'\")\n",
        "doc = nlp_ner(test_dataset)\n",
        "\n",
        "colors = {\"PER\": \"#F67DE3\", \"LOC\": \"#7DF6D9\", \"MISC\" : \"#FFFFFF\"}\n",
        "options = {\"colors\": colors} \n",
        "\n",
        "show_ents(doc)\n",
        "\n",
        "#spacy.displacy.render(doc, style=\"ent\", options= options, jupyter=True)"
      ],
      "metadata": {
        "id": "WIboT-raIcVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A titre de comparaison, test avec ce même texte mais à partir du modèle de base fourni par Spacy, fr_core_news_sm.**"
      ],
      "metadata": {
        "id": "J__jlCB0JEh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = 'fr_core_news_sm' \n",
        "nlp = spacy.load(pipeline)\n",
        "doc = nlp(test_dataset)\n",
        "show_ents(doc)"
      ],
      "metadata": {
        "id": "tco1K5ndJUF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarque 1. lors de la mise à jour du modèle NER (idem pour d'autres couches comme POS) avec les annotations de l'utilisateur, un processus itératif se met en place afin de faire converger les prédictions faites (des poids) vers des valeurs optimales vis-à-vis des annotations de référence. A caque itération, on calcule le \"gradient\" qui correspond, en optimisation, aux dérivées partielles de la fonction de classification non linéaire recherchée (voir [1], vous trouverez aussi la notion de backpropagation clé dans ces approches de DL pour le TAL). Pour observer la manière dont la valeur du gradient évolue (et se stabilise) lors des itérations, il est conseillé de regarder le paramètre \"losses\" mis à jour par la méthode update(..., losses=losses).\n",
        "[1]: https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/handouts/CS224N_DeepNLP_Week7_lecture3.pdf \n",
        "Aussi : https://spacy.io/usage/training\n",
        "\n",
        "Remarque 2. Pour éviter le surapprentissage (overfitting) d'un modèle : vous pouvez identifier que votre modèle n'est pas bon lorsqu'il fonctionne bien sur les données d'entraînement mais ne donne pas de bons résultats sur des données nouvelles et non encore vues. Autrement dit, le modèle \"mémorise\" les données d'apprentissage et n'est pas performant avec les nouvelles données."
      ],
      "metadata": {
        "id": "2A40a-xmOa9J"
      }
    }
  ]
}